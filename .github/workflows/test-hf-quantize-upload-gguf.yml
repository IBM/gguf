# This workflow generates quantized GGUF models from the original model (safetensors) from HF.
# For a given instance (i.e., HF model id (repo) and quantization):
# - Checks out (clones) the current source code repository
# - Sets environment variables used in the workflow
# - Sets up a Python 3.11 environment
# - Shallow clones the llama.cpp project (master branch)
# - Installs llama.cpp python conversion script dependencies 
# - downloads the designated model from (public) HF; primarily this are the *.safetensor files
# - Conversion (normalization): converts HF model (safetensors) to GGUF format (normalized to f16)
# - Quantization: converts the f16 GGUF to the designated quantization (e.g., Q4_0, Q4_K_M, etc.)
# - IN-PROGRESS: publish the result to a release (TODO, support private repo. and secret token)
# - TODO: push to an IBM HF repo. (collection) specifically for GGUF formatted Granite models

name: test-hf-quantize-upload-gguf

on:
  # Assure repos. have been created before any uploads (by ref. workflow)
  workflow_dispatch:       
 
permissions:
  contents: write
  packages: write

env:
  EXT_GGUF: .gguf
  EXT_NAME_F16: "-f16.gguf"
  FIND_ARGS: "-not -path '*/.*' -print | sed -e 's;[^/]*/;|___;g;s;___|; |;g'"
  LLAMACPP_DIR: llama.cpp
  MODEL_DOWNLOAD_DIR: models
  TARGET_REPO_NAME_EXT: -GGUF
  TARGET_REPO_OWNER: mrutkows # ibm-research
  F16_OPT_ENABLED: true
  FILE_EXISTS: "0"

# Full matrix (Ollama):
# repo_id: [
#   "ibm-granite/granite-3.0-2b-instruct", 
#   "ibm-granite/granite-3.0-8b-instruct",
#   "ibm-granite/granite-3.0-3b-a800m-instruct",
#   "ibm-granite/granite-3.0-1b-a400m-instruct",
#   "ibm-granite/granite-guardian-3.0-2b",
#   "ibm-granite/granite-guardian-3.0-8b", 
# ]
# quantization: [
#   "Q2_K", 
#   "Q3_K_L", "Q3_K_M", "Q3_K_S", 
#   "Q4_0", "Q4_1", "Q4_K_M", "Q4_K_S", 
#   "Q5_0", "Q5_1", "Q5_K_M", "Q5_K_S", 
#   "Q6_K", 
#   "Q8_0",
#]
jobs:
  build:
    permissions:
      contents: write
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        repo_id: [
          "ibm-granite/granite-3.0-1b-a400m-instruct",                  
        ]
        quantization: [
          "Q4_K_M", 
        ]

    steps:
    - uses: actions/checkout@v4

    - name: Dump runner context
      env:
        RUNNER_CONTEXT: ${{ toJson(runner) }}
      run: echo "$RUNNER_CONTEXT"

    - name: Dump GitHub context
      env:
        GITHUB_CONTEXT: ${{ toJson(github) }}
      run: echo "$GITHUB_CONTEXT"           
    
    # echo "$USER_ENV"  
    - name: confirm-environment
      run: |
        uname -a
        echo "runner.os: ${{ runner.os }}"
        echo "runner.arch: ${{ runner.arch }}"
        echo "github.workspace: ${{ github.workspace}}"
        echo "matrix.repo_id: ${{ matrix.repo_id }}"   
        echo "matrix.quantization: ${{ matrix.quantization }}"  
        echo "env.EXT_GGUF: ${{env.EXT_GGUF}}"    
        echo "env.EXT_NAME_F16: ${{ env.EXT_NAME_F16 }}"    
        echo "env.FIND_ARGS: ${{env.FIND_ARGS}}"                           
        echo "env.LLAMACPP_DIR: ${{env.LLAMACPP_DIR}}"           
        echo "env.MODEL_DOWNLOAD_DIR: ${{env.MODEL_DOWNLOAD_DIR}}"        
        echo "env.TARGET_REPO_NAME_EXT: ${{env.TARGET_REPO_NAME_EXT}}"   
        echo "env.TARGET_REPO_OWNER: ${{env.TARGET_REPO_OWNER}}"    
        echo "env.F16_OPT_ENABLED: ${{ env.F16_OPT_ENABLED }}"   
      # echo "USER_ENV=${{ toJson(env) }}"       
      # echo "$USER_ENV"           

    # alias tree="find . -print | sed -e 's;[^/]*/;|___;g;s;___|; |;g'"    
    # To allow `alias` in the default, non-interactive shell override using `shopt`.
    - name: create-aliases
      if: runner.os == 'macOS'
      run: |
        shopt -s expand_aliases
        alias tree="find"

    # Note: at the current time, we cannot use Python versions > 3.11 due to HF and langchain deps.
    # Note: you can verify in a step using: run: python -c "import sys; print(sys.version)"
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    # Use this step to set values to the github context (shared across jobs/steps)
    # Note: using $GITHUB_OUTPUT sets values under the current step's namespace
    # whereas using $GITHUB_ENV sets values in the job's underlying environment.
    # Note: for each 'repo_id' we parse out e.g., REPO_ORG=ibm-granite REPO_NAME=granite-3.0-2b-instruct
    - name: set-github-env
      id: set_github_env
      run: |
        echo "working_dir=$(pwd)" >> $GITHUB_OUTPUT      
        echo "working_dir=$(pwd)" >> $GITHUB_ENV        
        echo "REPO_ORG=$(dirname '${{ matrix.repo_id }}')" >> $GITHUB_ENV
        echo "REPO_NAME=$(basename '${{ matrix.repo_id }}')" >> $GITHUB_ENV
    
    - name: set-derivative-env-vars-1
      run: |    
        echo "BASE_FNAME_F16_GGUF=${{ env.REPO_NAME }}${{env.EXT_NAME_F16}}" >> $GITHUB_ENV
        echo "BASE_FNAME_QUANTIZED_GGUF=${{ env.REPO_NAME }}-${{matrix.quantization}}${{env.EXT_GGUF}}" >> $GITHUB_ENV        
        echo "LOCAL_MODEL_PATH=${{env.MODEL_DOWNLOAD_DIR}}/${{ matrix.repo_id }}" >> $GITHUB_ENV         

    - name: set-derivative-env-vars-2
      run: |       
        echo "LOCAL_FNAME_F16_GGUF=$MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/$BASE_FNAME_F16_GGUF" >> $GITHUB_ENV              
        echo "LOCAL_FNAME_QUANTIZED_GGUF=$MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/$BASE_FNAME_QUANTIZED_GGUF" >> $GITHUB_ENV                 
        echo "TARGET_REPO_ID=${{env.TARGET_REPO_OWNER}}/${{env.REPO_NAME}}${{env.TARGET_REPO_NAME_EXT}}" >> $GITHUB_ENV        

    - name: verify-github-env
      run: |   
        echo "================== GITHUB_OUTPUT ======================================="
        echo "steps.github_env.outputs.working_dir=${{ steps.set_github_env.outputs.working_dir }}"  
        echo "================== GITHUB_ENV =========================================="     
        echo "working_dir=$working_dir"
        echo "REPO_ORG=$REPO_ORG (${{ env.REPO_ORG }})"
        echo "REPO_NAME=$REPO_NAME (${{ env.REPO_NAME }})"  
        echo "================== Derivative Environment Variables 1 =================="           
        echo "BASE_FNAME_F16_GGUF='$BASE_FNAME_F16_GGUF' (${{ env.BASE_FNAME_F16_GGUF }})"                      
        echo "BASE_FNAME_QUANTIZED_GGUF='$BASE_FNAME_QUANTIZED_GGUF' (${{ env.BASE_FNAME_QUANTIZED_GGUF }})" 
        echo "LOCAL_MODEL_PATH='$LOCAL_MODEL_PATH' (${{ env.LOCAL_MODEL_PATH }})"           
        echo "================== Derivative Environment Variables 2 =================="              
        echo "LOCAL_FNAME_F16_GGUF='$LOCAL_FNAME_F16_GGUF' (${{ env.LOCAL_FNAME_F16_GGUF }})"          
        echo "LOCAL_FNAME_QUANTIZED_GGUF='$LOCAL_FNAME_QUANTIZED_GGUF' (${{ env.LOCAL_FNAME_QUANTIZED_GGUF }})"   
        echo "TARGET_REPO_ID='$TARGET_REPO_ID' (${{ env.TARGET_REPO_ID }})"   

    - name: install-hf-dependencies
      run: |
        python -m pip install -r ./requirements.txt
        pip list   

    - name: test-f16-exists
      if: env.F16_OPT_ENABLED == 'true'
      run: |
        output=$(python ./scripts/hf_model_file_exists.py ${{ env.TARGET_REPO_ID }} ${{ env.BASE_FNAME_F16_GGUF }} ${{secrets.HF_TOKEN}})   
        echo "output: '$output'"
        if [[ "$output" == "True" ]]; then
          echo "FILE_EXISTS=1" >> $GITHUB_ENV
        elif [[ "$output" == "False" ]]; then
          echo "FILE_EXISTS=0" >> $GITHUB_ENV
        else
          echo "Unexpected output from Python script: $output"
          exit 2
        fi

    - name: file-exists-test
      run: |    
        echo "FILE_EXISTS='$FILE_EXISTS' (${{ env.FILE_EXISTS }})"  

    - name: download-f16-gguf-hf-hub-download
      if: env.FILE_EXISTS == '1' && false
      run: |    
        echo "FILE_EXISTS='$FILE_EXISTS' (${{ env.FILE_EXISTS }})"     
        echo "--------------------"
        python ./scripts/hf_file_download.py ${{ env.MODEL_DOWNLOAD_DIR}} ${{ env.TARGET_REPO_ID }} ${{ env.BASE_FNAME_F16_GGUF }} ${{secrets.HF_TOKEN}}
        ls -al ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/*.gguf    
        echo "LOCAL_FNAME_F16_GGUF=${{ env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/${{ env.BASE_FNAME_F16_GGUF }}" >> $GITHUB_ENV

    - name: download-f16-gguf-hf-snapshot-download
      if: env.FILE_EXISTS == '1' && false
      run: |    
        echo "FILE_EXISTS='$FILE_EXISTS' (${{ env.FILE_EXISTS }})"     
        echo "--------------------"
        python ./scripts/hf_file_download.py ${{ env.MODEL_DOWNLOAD_DIR}} ${{ env.TARGET_REPO_ID }} ${{ env.BASE_FNAME_F16_GGUF }} ${{secrets.HF_TOKEN}}
        ls -al ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/*.gguf    
        echo "LOCAL_FNAME_F16_GGUF=${{ env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/${{ env.BASE_FNAME_F16_GGUF }}" >> $GITHUB_ENV                     

    # curl -C - -f --output-dir . -o test-curl.gguf -L https://huggingface.co/mrutkows/granite-3.0-1b-a400m-instruct-GGUF/resolve/main/granite-3.0-1b-a400m-instruct-f16.gguf
    # --create-dirs
    - name: download-f16-curl
      if: env.FILE_EXISTS == '1' && true
      run: |    
        echo "Downloading using curl..."     
        echo "--------------------"        
        curl -C - -f --create-dirs -o ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/${{ env.BASE_FNAME_F16_GGUF }} -L https://huggingface.co/${{ env.TARGET_REPO_ID }}/resolve/main/${{ env.BASE_FNAME_F16_GGUF }}
        echo "--------------------"        
        echo verifying...
        find ${{env.MODEL_DOWNLOAD_DIR}} ${{env.FIND_ARGS}}  
        ls -al ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}        
        echo "LOCAL_FNAME_F16_GGUF=${{ env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/${{ env.BASE_FNAME_F16_GGUF }}" >> $GITHUB_ENV        

    # for GGUF conversion, we only need a shallow copy (depth=1) and
    # specify only the scripts and requirements files we need (sparse).
    # Note: we include LICENSE for future BOM generation
    - name: shallow-clone-llamacpp
      uses: actions/checkout@v4
      with:
        path: ${{ env.LLAMACPP_DIR }} # checkout under this directory
        repository: 'ggerganov/llama.cpp'
        ref: 'master'  # default to master branch
        fetch-depth: 1
        sparse-checkout-cone-mode: false
        sparse-checkout: |
          LICENSE
          convert_hf_to_gguf.py
          convert_lora_to_gguf.py
          requirements/requirements-convert_legacy_llama.txt
          requirements/requirements-convert_hf_to_gguf.txt
          requirements/requirements-convert_lora_to_gguf.txt
          gguf-py
          scripts

    - name: print-llamacpp
      run: |
        echo "PATH: '{{$PATH}}'"
        ls -al llama.cpp
        find llama.cpp ${{env.FIND_ARGS}}
     
    - name: install-dependencies
      run: |
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_hf_to_gguf.txt
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_lora_to_gguf.txt
        pip list        
        
    - name: download-f16-gguf-curl
      if: env.FILE_EXISTS == '1' && false
      run: |    
        echo "FILE_EXISTS='$FILE_EXISTS' (${{ env.FILE_EXISTS }})"     
        echo "--------------------"        
        mkdir -p ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}
        chmod -R +rw ${{env.MODEL_DOWNLOAD_DIR}}        
        find ${{env.MODEL_DOWNLOAD_DIR}} ${{env.FIND_ARGS}}
        ./llama.cpp/scripts/hf.sh --repo ${{ env.TARGET_REPO_ID }} --file ${{ env.BASE_FNAME_F16_GGUF }} --outdir ${{ env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}
        echo verifying...
        find ${{env.MODEL_DOWNLOAD_DIR}} ${{env.FIND_ARGS}}  
        ls -al ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}        
        echo "LOCAL_FNAME_F16_GGUF=${{ env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/${{ env.BASE_FNAME_F16_GGUF }}" >> $GITHUB_ENV        

    - name: download-model-snapshot
      if: env.FILE_EXISTS == '0'
      run: |                         
        python ./scripts/hf_model_download_snapshot.py $MODEL_DOWNLOAD_DIR $REPO_ORG $REPO_NAME
        find models ${{env.FIND_ARGS}}          

    - name: convert-hf-to-gguf
      if: env.FILE_EXISTS == '0'
      run: |
        python ./llama.cpp/convert_hf_to_gguf.py ${{ env.LOCAL_MODEL_PATH }} --outfile ${{ env.LOCAL_FNAME_F16_GGUF }} --verbose
        ls -al ${{ env.LOCAL_MODEL_PATH }}/*.gguf

    - name: print-storage-memory-info
      run: |
        df
        echo "--------------------"         
        xcodebuild -version        
        clang --version
        echo "--------------------"      
        top -l 1 | grep -E "^CPU|^PhysMem"  
        echo "--------------------"    
        ls -alS -d */       
        ls -alS ${{env.MODEL_DOWNLOAD_DIR}}   
        ls -alS ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }} 
        ls -alS ${{env.MODEL_DOWNLOAD_DIR}}/${{ env.TARGET_REPO_ID }}/*.gguf      
        echo "--------------------"                    
        find . ${{env.FIND_ARGS}}        

    - name: quantize-gguf
      run: |      
        echo "--------------------"             
        echo "LOCAL_FNAME_F16_GGUF='$LOCAL_FNAME_F16_GGUF' (${{ env.LOCAL_FNAME_F16_GGUF }})"  
        echo "LOCAL_FNAME_QUANTIZED_GGUF='$LOCAL_FNAME_QUANTIZED_GGUF' (${{ env.LOCAL_FNAME_QUANTIZED_GGUF }})"          
        echo "--------------------"          
        ./bin/llama-quantize ${{ env.LOCAL_FNAME_F16_GGUF }} ${{ env.LOCAL_FNAME_QUANTIZED_GGUF }} ${{matrix.quantization}}
        ls -al ${{ env.LOCAL_MODEL_PATH }}/*.gguf         

    - name: upload-model-gguf
      run: |         
        python ./scripts/hf_model_upload.py ${{ env.TARGET_REPO_ID }} ${{ env.LOCAL_FNAME_QUANTIZED_GGUF }} ${{secrets.HF_TOKEN}} ${{github.workflow_ref}} ${{github.run_id}}       
