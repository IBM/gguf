# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Python package

#on:
#  release:
#    types: [created]
#  workflow_dispatch:

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  LLAMACPP_DIR: llama.cpp

jobs:
  build:

    # runs-on: ubuntu-latest
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11"]

    steps:
    - uses: actions/checkout@v4
    - name: confirm-os-arch
      run: |
        uname -a
        echo "Operating System: ${{ runner.os }}"
        echo "Architecture: ${{ runner.arch }}"
        echo "python-version: ${{ matrix.python-version }}"

    - name: alias-tree
      if: matrix.os == 'macos-latest'
      run: |
        alias tree="find . -print | sed -e 's;[^/]*/;|___;g;s;___|; |;g'"
        tree
    
    # or 'macOS'
    - name: apt-get tree
      if: ${{ contains(runner.os, 'ubuntu') }}      
      run: |
        sudo apt-get update
        sudo apt-get install -y tree        

    # - name: install-linux-commands
    #   run: |
    #     sudo apt-get update
    #     sudo apt-get install -y tree
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: display-python-version
      run: python -c "import sys; print(sys.version)"        
    - name: shallow-clone-llamacpp
      uses: actions/checkout@v4
      with:
        path: ${{ env.LLAMACPP_DIR }}
        repository: 'ggerganov/llama.cpp'  # Replace with the desired repository owner and name
        ref: 'master'  # Specify a branch to checkout
        fetch-depth: 1
        sparse-checkout-cone-mode: false
        sparse-checkout: |
          LICENSE
          convert_hf_to_gguf.py
          convert_lora_to_gguf.py
          requirements/requirements-convert_legacy_llama.txt
          requirements/requirements-convert_hf_to_gguf.txt
          requirements/requirements-convert_lora_to_gguf.txt
          gguf-py
          scripts

    - name: print-llamacpp
      run: |
        echo $PATH
        tree ${{ env.LLAMACPP_DIR }}
 
    - name: install-dependencies
      run: |
        python -m pip install -r ./requirements.txt
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_hf_to_gguf.txt
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_lora_to_gguf.txt
        pip list

    - name: download-model
      run: |
        python ./scripts/download_model_from_hf.py ibm-granite granite-3.0-8b-instruct

    - name: convert-hf-to-gguf
      run: |
        python /llama.cpp/convert_hf_to_gguf.py \          
           ./models/ibm-granite/granite-3.0-8b-instruct/ --outfile test.gguf --verbose
        tree   

    # - name: convert-lora-to-gguf
    #   run: |
    #     python ./llamacpp/convert_lora_to_gguf.py \

    #- name: Lint with flake8
    #  run: |
    # python -m pip install --upgrade pip
    # python -m pip install flake8 pytest
    #    # stop the build if there are Python syntax errors or undefined names
    #    flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    #    # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
    #    flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    #- name: Test with pytest
    #  run: |
    #    pytest
