# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Python package

#on:
#  release:
#    types: [created]
#  workflow_dispatch:

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  LLAMACPP_DIR: llama.cpp
  MODEL_DOWNLOAD_DIR: models
  FIND_ARGS: "-not -path '*/.*' -print | sed -e 's;[^/]*/;|___;g;s;___|; |;g'"
  EXT_GGUF: .gguf
  EXT_NAME_F16: "-f16.gguf"

jobs:
  build:
    # runs-on: ubuntu-latest
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        repo_id: ["ibm-granite/granite-3.0-2b-instruct"]
        quantization: ["Q4_0","Q4_K_M"]

    steps:
    - uses: actions/checkout@v4
    - name: confirm-environment
      run: |
        uname -a
        echo "Operating System: ${{ runner.os }}"
        echo "Architecture: ${{ runner.arch }}"
        echo "repo_id: ${{ matrix.repo_id }}"    
        echo "quantization: ${{ matrix.quantization }}"    
        echo "EXT_GGUF: ${{env.EXT_GGUF}}"
        echo "EXT_NAME_F16: ${{env.EXT_NAME_F16}}"

    # alias tree="find . -print | sed -e 's;[^/]*/;|___;g;s;___|; |;g'"    
    # To allow `alias` in the default, non-interactive shell override using `shopt`.
    - name: create-aliases
      if: runner.os == 'macOS'
      run: |
        shopt -s expand_aliases
        alias tree="find"

    # Note: at the current time, we cannot use Python versions > 3.11 due to HF and langchain deps.
    # Note: you can verify in a step using: run: python -c "import sys; print(sys.version)"
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    # Use this step to set values to the github context (shared across jobs/steps)
    # Note: using $GITHUB_OUTPUT sets values under the current step's namespace
    # whereas using $GITHUB_ENV sets values in the job's underlying environment.
    - name: set-github-env
      id: github_env
      run: |
        echo "working_dir=$(pwd)" >> $GITHUB_OUTPUT
        echo "working_dir=$(pwd)" >> $GITHUB_ENV        
        echo "REPO_ORG=$(dirname '${{ matrix.repo_id }}')" >> $GITHUB_ENV
        echo "REPO_NAME=$(basename '${{ matrix.repo_id }}')" >> $GITHUB_ENV

    - name: verify-github-env
      run: |   
        echo "outputs.working_dir=${{ steps.github_env.outputs.working_dir }}"      
        echo "working_dir=$working_dir"
        echo "REPO_ORG=$REPO_ORG"
        echo "REPO_NAME=$REPO_NAME"

    # for GGUF conversion, we only need a shallow copy (depth=1) and
    # specify only the scripts and requirements files we need (sparse).
    # Note: we include LICENSE for future BOM generation
    - name: shallow-clone-llamacpp
      uses: actions/checkout@v4
      with:
        path: ${{ env.LLAMACPP_DIR }} # checkout under this directory
        repository: 'ggerganov/llama.cpp'
        ref: 'master'  # default to master branch
        fetch-depth: 1
        sparse-checkout-cone-mode: false
        sparse-checkout: |
          LICENSE
          convert_hf_to_gguf.py
          convert_lora_to_gguf.py
          requirements/requirements-convert_legacy_llama.txt
          requirements/requirements-convert_hf_to_gguf.txt
          requirements/requirements-convert_lora_to_gguf.txt
          gguf-py
          scripts

    - name: print-llamacpp
      run: |
        echo "PATH: '{{$PATH}}'"
        ls -al llama.cpp
        find llama.cpp ${{env.FIND_ARGS}}
 
    - name: install-dependencies
      run: |
        python -m pip install -r ./requirements.txt
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_hf_to_gguf.txt
        python -m pip install -r ./llama.cpp/requirements/requirements-convert_lora_to_gguf.txt
        pip list      

    # echo "output_dir='$MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}'"     
    # echo "repo_id: $REPO_ID"  
    # echo "output_dir=$output_dir"   
    - name: download-model
      run: |
        echo "MODEL_DOWNLOAD_DIR: ${{env.MODEL_DOWNLOAD_DIR}}"
        echo "repo_id: ${{ matrix.repo_id }}"   
        echo "quantization: ${{ matrix.quantization }}"                         
        echo "========" 
        echo "outputs.working_dir=${{ steps.github_env.outputs.working_dir }}"      
        echo "working_dir=$working_dir"
        echo "REPO_ORG=$REPO_ORG"
        echo "REPO_NAME=$REPO_NAME"                            
        python ./scripts/download_model_from_hf.py $MODEL_DOWNLOAD_DIR $REPO_ORG $REPO_NAME
        find models ${{env.FIND_ARGS}}

    - name: convert-hf-to-gguf
      run: |
        python ./llama.cpp/convert_hf_to_gguf.py $MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }} --outfile $MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/${{ env.REPO_NAME }}${{env.EXT_NAME_F16}}${{env.EXT_GGUF}} --verbose
        echo "FNAME_F16_GGUF=$MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/${{ env.REPO_NAME }}${{env.EXT_NAME_F16}}${{env.EXT_GGUF}}" >> $GITHUB_ENV
        ls -al $MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/*.gguf

    - name: quantize-gguf
      run: |   
        echo "FNAME_F16_GGUF='$FNAME_F16_GGUF'"
        exit 0   
        ./bin/llama-quantize $FNAME_F16_GGUF $MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/${{ env.REPO_NAME }}-${{matrix.quantization}}${{env.EXT_GGUF}} ${{matrix.quantization}}
        ls -al $MODEL_DOWNLOAD_DIR/${{ matrix.repo_id }}/*.gguf
